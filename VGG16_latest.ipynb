{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salma-abed/Deep-learning-based-automated-detection-and-classification-of-Alzheimer-s-disease-Using-Neuroimaging/blob/main/VGG16_latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYJAxh5vKe9Y"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from shutil import copyfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-FC6xhcKlwR",
        "outputId": "d2f2edba-8c4d-4eba-c26e-af5d0bfefb23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP4KcpZQK0mS"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/MyDrive/output_images_preprocessed'\n",
        "train_path = '/content/drive/MyDrive/output_images_preprocessed/train'\n",
        "test_path = '/content/drive/MyDrive/output_images_preprocessed/test'\n",
        "label_names = ['AD', 'CN', 'LMCI', 'MCI']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UUd3RxXK6WW"
      },
      "outputs": [],
      "source": [
        "class VGG16Model:\n",
        "    def __init__(self, train_path, test_path, label_names, train_data=None, test_data=None):\n",
        "        # Initialize the object's data members\n",
        "        self.train_path = train_path\n",
        "        self.test_path = test_path\n",
        "        self.label_names = label_names\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "        self.model = None\n",
        "        \n",
        "    def build_model(self):\n",
        "        # Define the VGG16 model architecture\n",
        "        self.model = tf.keras.applications.VGG16(\n",
        "            include_top=True,    # whether to include the fully connected layer on top of the network\n",
        "            weights=None,        # use random initialization for the weights\n",
        "            input_shape=(224, 224, 3),   # specify the shape of the input image tensor\n",
        "            classes=len(self.label_names)  # specify the number of output classes\n",
        "        )\n",
        "        \n",
        "    def prepare_data(self):\n",
        "        # Define the data generators for training and testing\n",
        "        train_datagen = ImageDataGenerator(rescale=1.0 / 255)    # rescale pixel values to [0, 1] for training data\n",
        "        test_datagen = ImageDataGenerator(rescale=1.0 / 255)     # rescale pixel values to [0, 1] for testing data\n",
        "        \n",
        "        # Set up the training data generator\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            directory=self.train_path,           # directory containing the training data\n",
        "            classes=self.label_names,            # list of label names for the dataset\n",
        "            batch_size=32,                       # batch size for training\n",
        "            shuffle=True,                        # shuffle the training data after each epoch\n",
        "            seed=42,                             # set the random seed for shuffling the training data\n",
        "            target_size=(224, 224),              # resize input images to 224x224 pixels\n",
        "        )\n",
        "        \n",
        "        # Set up the testing data generator\n",
        "        test_generator = test_datagen.flow_from_directory(\n",
        "            directory=self.test_path,            # directory containing the testing data\n",
        "            classes=self.label_names,            # list of label names for the dataset\n",
        "            batch_size=32,                       # batch size for testing\n",
        "            shuffle=True,                        # shuffle the testing data after each epoch\n",
        "            seed=42,                             # set the random seed for shuffling the testing data\n",
        "            target_size=(224, 224),              # resize input images to 224x224 pixels\n",
        "        )\n",
        "        \n",
        "        # Assign the data generators to the training and testing sets\n",
        "        self.train_data = train_generator\n",
        "        self.test_data = test_generator\n",
        "        \n",
        "    def train_model(self, epochs=10, optimizer='adam'):\n",
        "        # Compile the model with an optimizer, loss function, and evaluation metric\n",
        "        self.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        \n",
        "        # Train the model using the training data generator\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        self.model.fit(self.train_data, epochs=epochs)\n",
        "        \n",
        "    def evaluate_model(self):\n",
        "        # Evaluate the model on the testing data generator\n",
        "        loss, acc = self.model.evaluate(self.test_data)\n",
        "        print(f\"Test accuracy: {acc:.2f}\")\n",
        "        \n",
        "    def predict(self, image_path):\n",
        "        # Load the image from the specified file path and resize it to 224x224 pixels\n",
        "        img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "        \n",
        "        # Convert the image to a numpy array and add a batch dimension\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    def display_summary(self):\n",
        "      if self.model is None:\n",
        "          print(\"Model has not been built yet. Please call build_model() first.\")\n",
        "      else:\n",
        "          vgg16_model = tf.keras.applications.VGG16(\n",
        "              include_top=True,\n",
        "              weights=None,\n",
        "              input_shape=(224, 224, 3),\n",
        "              classes=len(self.label_names)\n",
        "          )\n",
        "          vgg16_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XPFjmMaLGNv",
        "outputId": "dec6c84f-6c58-4b5a-91a6-eff75a859c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3170 images belonging to 4 classes.\n",
            "Found 800 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the ResNet50Model class\n",
        "model = VGG16Model(train_path=train_path, test_path=test_path, label_names=label_names)\n",
        "\n",
        "# Build the model architecture\n",
        "model.build_model()\n",
        "\n",
        "# Prepare the data generators\n",
        "model.prepare_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqNh36okLLTp",
        "outputId": "ab6f6521-48bc-43d0-9735-4f2219186136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 4)                 16388     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,276,932\n",
            "Trainable params: 134,276,932\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.display_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG188inULNeG",
        "outputId": "48fef67d-83c2-420f-edfd-9505749cbe25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 1580s 16s/step - loss: 1.3949 - accuracy: 0.2489\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 40s 401ms/step - loss: 1.3865 - accuracy: 0.2467\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 39s 393ms/step - loss: 1.3864 - accuracy: 0.2353\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 40s 397ms/step - loss: 1.3863 - accuracy: 0.2397\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3864 - accuracy: 0.2416\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3863 - accuracy: 0.2401\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3864 - accuracy: 0.2476\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3863 - accuracy: 0.2483\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3863 - accuracy: 0.2476\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 40s 396ms/step - loss: 1.3863 - accuracy: 0.2407\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3864 - accuracy: 0.2448\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3864 - accuracy: 0.2397\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3863 - accuracy: 0.2558\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3864 - accuracy: 0.2524\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 1.3864 - accuracy: 0.2524\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f666435efd0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Train the model\n",
        "model.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.model.fit(model.train_data, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSE8LYJK1H_s",
        "outputId": "3a5ea32b-a673-430a-8d4d-002bbcc27573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 371s 15s/step - loss: 1.3863 - accuracy: 0.2500\n",
            "Test accuracy: 0.25\n"
          ]
        }
      ],
      "source": [
        "model.evaluate_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "CTtAu2Lp49DX",
        "outputId": "1646e5b8-5c15-45be-b715-cac130ff13e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 3s 116ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f596b1a83a0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted labels\n",
        "y_pred_probs = model.model.predict(model.test_data)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "labels = [\"AD\", \"CN\", \"LMCI\",\"MCI\"]\n",
        "y_test = model.test_data.labels\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix= result, display_labels= labels)\n",
        "disp.plot()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}