{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salma-abed/Deep-learning-based-automated-detection-and-classification-of-Alzheimer-s-disease-Using-Neuroimaging/blob/main/multilayer_per.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie1uWIxInlnc"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-Rgx_VDntZm"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from sklearn import preprocessing\n",
        "from keras_preprocessing.image import load_img\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKhA1hYT2kSt",
        "outputId": "cf8a616e-6f8e-4bae-db40-8f3d12c6040a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yb-TigE35la"
      },
      "outputs": [],
      "source": [
        "size = 32\n",
        "train_images = []\n",
        "train_labels = []\n",
        "for directory_path in glob.glob(\"/content/drive/MyDrive/full/train/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    # print('\\n')\n",
        "    # print('\\n')\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        # print(img_path)\n",
        "        img = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # you can omit this line whenever you want to work on colored images\n",
        "        img = cv2.resize(img,(size,size))\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "       # print(label)\n",
        "\n",
        "      \n",
        "\"\"\"Note: Better to work with (numpy) array than a normal list as in the normal\n",
        "list we will have to iterate over all the elements using a loop\n",
        "\"\"\"\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0MdRAtg37lM"
      },
      "outputs": [],
      "source": [
        "test_images = []\n",
        "test_labels = []\n",
        "for directory_path in glob.glob(\"/content/drive/MyDrive/full/test/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    for img_path in glob.glob(os.path.join(directory_path, '*.jpg')):\n",
        "        # print(img_path)\n",
        "        img = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # you can omit this line whenever you want to work on colored images\n",
        "        img = cv2.resize(img,(size,size))\n",
        "        test_images.append(img)\n",
        "        test_labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quj1d4vI39w9",
        "outputId": "4897ee3b-67cf-4794-ae16-4d9932de354f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels)\n",
        "test_labels_encoded = le.transform(test_labels)\n",
        "le.fit(train_labels)\n",
        "train_labels_encoded = le.transform(train_labels)\n",
        "print(train_labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM8RXCUg3_c1"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Here we reassingned the variables to new names as they are more meaningful(That is not actual splitting)\n",
        "The splitting was already done\n",
        "'''\n",
        "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kkwqxn9n4BVv"
      },
      "outputs": [],
      "source": [
        "# Normalize pixel values to between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRNyFbLOHqE3",
        "outputId": "0df0bbd3-0b16-4fa3-8ecd-8141bf3c3d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5119, 32, 32)\n",
            "(1281, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TxF18dZ4YrF"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "# model.add(Dense(units=64, activation='relu', input_dim=100))\n",
        "# model.add(Dense(units=10, activation='softmax'))\n",
        "# model= MLPClassifier(random_state=5,verbose=True,learning_rate_init=0.01,activation='relu',solver='sgd',epochs=10,)\n",
        "model.add(Flatten(input_shape=(size,size))) # you can add 3 as a 3d dimension to this function\n",
        "model.add(Dense((size*size),kernel_initializer = 'uniform')) \n",
        "model.add(Dense(6,kernel_initializer = 'uniform', activation = 'relu')) \n",
        "model.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid')) \n",
        "model.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
        "\n",
        "# Compile the model\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# mlp= MLPClassifier(hidden_layer_sizes=(100,100,100),random_state=5,verbose=True,learning_rate_init=0.01,activation='relu',solver='sgd')\n",
        "# mlp.fit(x_train, y_train)\n",
        "# y_predict= mlp.predict(x_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8ZotrMHmKrQ",
        "outputId": "0fdff822-82dd-49d8-81d7-bff37cdc38fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0104\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf06595550>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "#model.fit(x_train, y_train, epochs=15, batch_size=32)\n",
        "# model.fit(tf.expand_dims(x_train, axis=-1),y_train,epochs=10)\n",
        "model.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPJJWI7O55X4",
        "outputId": "4a9628c0-e0ee-4d28-b232-6c2c6e667564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0975\n",
            "11/11 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.1405\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "#model.fit(x_train, y_train, epochs=15, batch_size=32)\n",
        "# model.fit(tf.expand_dims(x_train, axis=-1),y_train,epochs=10)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss_and_metrics = model.evaluate(x_test, y_test,batch_size=128)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "481ac8f22f00f9fe5d3af33b16d98348d626eaa1f948c14304d9079b2ff7610c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
