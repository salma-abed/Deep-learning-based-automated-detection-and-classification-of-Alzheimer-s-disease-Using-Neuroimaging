{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2q_mn5EhtcD"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "m4NckONPh4Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = 224\n",
        "train_images = []\n",
        "train_labels = []\n",
        "for directory_path in glob.glob(\"/content/drive/MyDrive/full/train/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    # print('\\n')\n",
        "    # print('\\n')\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        # print(img_path)\n",
        "        img = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img,(size,size))\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "       # print(label)\n",
        "\n",
        "      \n",
        "\"\"\"Note: Better to work with (numpy) array than a normal list as in the normal\n",
        "list we will have to iterate over all the elements using a loop\n",
        "\"\"\"\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "XUk9tuUuh8c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []\n",
        "for directory_path in glob.glob(\"/content/drive/MyDrive/full/test/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    for img_path in glob.glob(os.path.join(directory_path, '*.jpg')):\n",
        "        # print(img_path)\n",
        "        img = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img,(size,size))\n",
        "        test_images.append(img)\n",
        "        test_labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "mbSIN_b8h-yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels)\n",
        "test_labels_encoded = le.transform(test_labels)\n",
        "le.fit(train_labels)\n",
        "train_labels_encoded = le.transform(train_labels)\n",
        "print(train_labels_encoded)"
      ],
      "metadata": {
        "id": "C9Eq5mkUiCyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Here we reassingned the variables to new names as they are more meaningful(That is not actual splitting)\n",
        "The splitting was already done\n",
        "'''\n",
        "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
      ],
      "metadata": {
        "id": "4mjhXiUkiFI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "Bp7ac09niIdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest = RandomForestClassifier(criterion='gini',\n",
        "                                 n_estimators=5,\n",
        "                                 random_state=1,\n",
        "                                 n_jobs=2)"
      ],
      "metadata": {
        "id": "76HNI7BWjQfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "x_train = x_train.reshape(5119,3*224*224)\n",
        "x_test = x_test.reshape(1281,3*224*224)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "qyuWl1rzkeTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "QNOZ3nrHjaW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest.score(x_train,y_train)"
      ],
      "metadata": {
        "id": "qj3RsDI2k3zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = forest.predict(x_test)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "nZPL78cmkqc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qiezY4qlrI4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "2Fn-FpTvtO7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels = [\"Mild\", \"Modrate\", \"None\",\"Very Mild\"]\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9JHKsFCJoCt9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}